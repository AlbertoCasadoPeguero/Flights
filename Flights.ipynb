{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Data Science Club Reto Mensual - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para este primer reto tenemos el dataset del Departamento de Transporte de USA (DoT) donde debemos analizar y tratar de reducir el numero de cancelacion de vuelos y mejorar la esperiencia de los viajantes. El reto es ayudar el DoT predecir si un vuelo sera cancelado o no con la data suministrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando las primeras librerias para iniciar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importanto la data y un primer vistazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\Python\\Machine Learning\\SDS Club Challenges\\September Challenge\\Data\\public_flights.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando los valores nulos o faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como los registros con valores faltantes son muy pocos, eliminarlos no nos afecta mucho (aunque esta opcion nunca debe ser la primera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.dropna()\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como es un problema de clasificacion verificamos nuestra variable dependiente o target, y podemos ver que tenemos un severo caso de clases desbalanceadas donde tenemos mas registros de una clase que de otra, y esto afectaria bastante a nuestro modelo, dando como resultado un modelo que solo sabe predecir que un vuelo sera cancelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(dataset['CANCELLED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunos de los metodos para poder lidiar con este tipo de problematicas, las cuales son muy comunes cuando se esta trabajando con problemas de clasificacion, son los siguientes:\n",
    "\n",
    " - Upsampling.\n",
    " - Downsampling.\n",
    " - Distintas metricas de evaluacion del modelo.\n",
    " \n",
    "### Upsampling: Consiste en duplicar los registros de la clase con menor ocurrencia para igualar a la de mayor ocurrencia, el problema con este metodo es que tiende a causar que el modelo se ajuste demasiado haciendo que en vez de aprender, memorice los datos, a esto se le llama Overfitting.\n",
    "\n",
    "### Downsampling: Consiste en tomar de forma aleatoria la misma cantidad de registros que tiene la clase de menor ocurrencia, de los registros de la clase con mayor ocurrencia, el problema con este es que perdemos data lo cual puede causar que nuestro modelo aprenda menos por la poca cantidad de registros, a esto se le conoce como Underfitting.\n",
    "\n",
    "### Distintas metricas: Este metodo consiste en no evaluar nuestro modelo con solamente una metrica, por ejemplo, exactitud de las predicciones (Accuracy), si no, utilizar otras herramientas como; Matriz de Confuncion, Precision, Recall y F1 Score. \n",
    "\n",
    "### Primero usare el metodo de downsampling, esto para poder realizar un EDA(Exploratory Data Analysis) con una data mas balanceada y tratar de entender un poco mas la data que tengo antes de proceder con la creacion del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#Primero hacemos la division de la data en cancelados y no cancelados\n",
    "cancelados = dataset[dataset['CANCELLED'] == 1]\n",
    "no_cancelados = dataset[dataset['CANCELLED'] == 0]\n",
    "\n",
    "print(f'Cantidad de registros de vuelos cancelados {len(cancelados)}')\n",
    "print(f'Cantidad de registros de vuelos no cancelados {len(no_cancelados)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Luego realizamos la seleccion aleatoria de la data creando un nuevo dataframe con los registros aleatorios\n",
    "#Y por ultimo lo unimos como un solo dataset con los registros que pertenecen a los cancelados\n",
    "data_downsampled = resample(no_cancelados, replace = False, n_samples = len(cancelados))\n",
    "dataset_downsampled = pd.concat([data_downsampled, cancelados])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora nuestro nuevo dataset esta mas balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(dataset_downsampled['CANCELLED'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
